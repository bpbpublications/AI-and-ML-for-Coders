{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# install Kubeflow\n",
        "!pip install kfp --upgrade -q"
      ],
      "metadata": {
        "id": "A09aPO8yElwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install UCI ML Repo\n",
        "!pip install ucimlrepo -q"
      ],
      "metadata": {
        "id": "XMXxiKOJ0ecs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import kfp\n",
        "from kfp import dsl\n",
        "from kfp.dsl import component"
      ],
      "metadata": {
        "id": "o9rFQod66YNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to load and preprocess data\n",
        "@component(base_image='python:3.9', packages_to_install=['pandas', 'numpy'])\n",
        "def load_and_preprocess_data() -> str:\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
        "    data = pd.read_csv(url, header=None)\n",
        "\n",
        "    columns = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \"word_freq_our\",\n",
        "               \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \"word_freq_order\", \"word_freq_mail\",\n",
        "               \"word_freq_receive\", \"word_freq_will\", \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\",\n",
        "               \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\",\n",
        "               \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\",\n",
        "               \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\",\n",
        "               \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\",\n",
        "               \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
        "               \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\",\n",
        "               \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\",\n",
        "               \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_#\", \"capital_run_length_average\",\n",
        "               \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]\n",
        "    data.columns = columns\n",
        "\n",
        "    # Save preprocessed data to CSV\n",
        "    data.to_csv('preprocessed_data.csv', index=False)\n",
        "    return 'preprocessed_data.csv'"
      ],
      "metadata": {
        "id": "-ygLx1fQ6YKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for exploratory data analysis\n",
        "@component(base_image='python:3.9', packages_to_install=['pandas', 'numpy'])\n",
        "def eda(preprocessed_data_path: str):\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    data = pd.read_csv(preprocessed_data_path)\n",
        "\n",
        "    # Print data information and description\n",
        "    print(data.info())\n",
        "    print(data.describe())\n",
        "\n",
        "    # Save the info and describe to a text file\n",
        "    with open('eda_output.txt', 'w') as f:\n",
        "        f.write(str(data.info()) + '\\n' + str(data.describe()))"
      ],
      "metadata": {
        "id": "mQfJAcVg6YHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for feature engineering\n",
        "@component(base_image='python:3.9', packages_to_install=['pandas', 'numpy', 'scikit-learn'])\n",
        "def feature_engineering(preprocessed_data_path: str) -> str:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    data = pd.read_csv(preprocessed_data_path)\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer_num = SimpleImputer(strategy='median')\n",
        "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "    numeric_features = data.select_dtypes(include=[np.number]).columns\n",
        "    categorical_features = data.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "    data[numeric_features] = imputer_num.fit_transform(data[numeric_features])\n",
        "    data[categorical_features] = imputer_cat.fit_transform(data[categorical_features])\n",
        "\n",
        "    # Splitting the data\n",
        "    X = data.drop('spam', axis=1)\n",
        "    y = data['spam']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardizing the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Save engineered features\n",
        "    np.savez('engineered_features.npz', X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
        "    return 'engineered_features.npz'"
      ],
      "metadata": {
        "id": "QBIk_ehW6YFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for model training\n",
        "@component(base_image='python:3.9', packages_to_install=['numpy', 'tensorflow', 'keras'])\n",
        "def model_training(engineered_features_path: str) -> str:\n",
        "    import numpy as np\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense\n",
        "    data = np.load(engineered_features_path)\n",
        "    X_train = data['X_train']\n",
        "    X_test = data['X_test']\n",
        "    y_train = data['y_train']\n",
        "    y_test = data['y_test']\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save('spam_classification_model.h5')\n",
        "\n",
        "    # Save the training history\n",
        "    np.savez('training_history.npz', history=history.history)\n",
        "    return 'spam_classification_model.h5'\n"
      ],
      "metadata": {
        "id": "Y4iIG_NX6X8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for evaluating the model\n",
        "@component(base_image='python:3.9', packages_to_install=['numpy', 'tensorflow', 'keras'])\n",
        "def model_evaluation(trained_model_path: str, engineered_features_path: str):\n",
        "    import numpy as np\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    data = np.load(engineered_features_path)\n",
        "    X_test = data['X_test']\n",
        "    y_test = data['y_test']\n",
        "\n",
        "    model = keras.models.load_model(trained_model_path)\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f'Test Loss: {loss}')\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "    history_data = np.load('/mnt/data/training_history.npz', allow_pickle=True)\n",
        "    history = history_data['history'].item()\n",
        "\n",
        "    plt.plot(history['loss'], label='train_loss')\n",
        "    plt.plot(history['val_loss'], label='val_loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('/mnt/data/loss_plot.png')"
      ],
      "metadata": {
        "id": "a2uRbcWh7s3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the pipeline\n",
        "@dsl.pipeline(\n",
        "    name='Spam Classification Pipeline',\n",
        "    description='A pipeline to train and classify emails as spam or not spam'\n",
        ")\n",
        "def spam_classification_pipeline():\n",
        "    preprocessed_data_task = load_and_preprocess_data()\n",
        "    eda(preprocessed_data_path=preprocessed_data_task.output)\n",
        "    engineered_features_task = feature_engineering(preprocessed_data_path=preprocessed_data_task.output)\n",
        "    trained_model_task = model_training(engineered_features_path=engineered_features_task.output)\n",
        "    model_evaluation(trained_model_path=trained_model_task.output, engineered_features_path=engineered_features_task.output)"
      ],
      "metadata": {
        "id": "XJDyKg5q8B2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the pipeline\n",
        "kfp.compiler.Compiler().compile(spam_classification_pipeline, 'spam_classification_pipeline.yaml')\n"
      ],
      "metadata": {
        "id": "Ix5GptUl8MYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check contents of the YAML file\n",
        "!cat spam_classification_pipeline.yaml"
      ],
      "metadata": {
        "id": "TEicaHL6Fg-4",
        "outputId": "a7778a0e-a3fd-4bf7-9e4b-4f8b171626da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# PIPELINE DEFINITION\n",
            "# Name: spam-classification-pipeline\n",
            "# Description: A pipeline to train and classify emails as spam or not spam\n",
            "components:\n",
            "  comp-eda:\n",
            "    executorLabel: exec-eda\n",
            "    inputDefinitions:\n",
            "      parameters:\n",
            "        preprocessed_data_path:\n",
            "          parameterType: STRING\n",
            "  comp-feature-engineering:\n",
            "    executorLabel: exec-feature-engineering\n",
            "    inputDefinitions:\n",
            "      parameters:\n",
            "        preprocessed_data_path:\n",
            "          parameterType: STRING\n",
            "    outputDefinitions:\n",
            "      parameters:\n",
            "        Output:\n",
            "          parameterType: STRING\n",
            "  comp-load-and-preprocess-data:\n",
            "    executorLabel: exec-load-and-preprocess-data\n",
            "    outputDefinitions:\n",
            "      parameters:\n",
            "        Output:\n",
            "          parameterType: STRING\n",
            "  comp-model-evaluation:\n",
            "    executorLabel: exec-model-evaluation\n",
            "    inputDefinitions:\n",
            "      parameters:\n",
            "        engineered_features_path:\n",
            "          parameterType: STRING\n",
            "        trained_model_path:\n",
            "          parameterType: STRING\n",
            "  comp-model-training:\n",
            "    executorLabel: exec-model-training\n",
            "    inputDefinitions:\n",
            "      parameters:\n",
            "        engineered_features_path:\n",
            "          parameterType: STRING\n",
            "    outputDefinitions:\n",
            "      parameters:\n",
            "        Output:\n",
            "          parameterType: STRING\n",
            "deploymentSpec:\n",
            "  executors:\n",
            "    exec-eda:\n",
            "      container:\n",
            "        args:\n",
            "        - --executor_input\n",
            "        - '{{$}}'\n",
            "        - --function_to_execute\n",
            "        - eda\n",
            "        command:\n",
            "        - sh\n",
            "        - -c\n",
            "        - \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip ||\\\n",
            "          \\ python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1\\\n",
            "          \\ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.8.0'\\\n",
            "          \\ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\\\"3.9\\\"'  &&\\\n",
            "          \\  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'numpy'\\\n",
            "          \\ && \\\"$0\\\" \\\"$@\\\"\\n\"\n",
            "        - sh\n",
            "        - -ec\n",
            "        - 'program_path=$(mktemp -d)\n",
            "\n",
            "\n",
            "          printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "\n",
            "          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\n",
            "          '\n",
            "        - \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import\\\n",
            "          \\ *\\n\\ndef eda(preprocessed_data_path: str):\\n    import pandas as pd\\n\\\n",
            "          \\    import numpy as np\\n    data = pd.read_csv(preprocessed_data_path)\\n\\\n",
            "          \\n    # Print data information and description\\n    print(data.info())\\n\\\n",
            "          \\    print(data.describe())\\n\\n    # Save the info and describe to a text\\\n",
            "          \\ file\\n    with open('eda_output.txt', 'w') as f:\\n        f.write(str(data.info())\\\n",
            "          \\ + '\\\\n' + str(data.describe()))\\n\\n\"\n",
            "        image: python:3.9\n",
            "    exec-feature-engineering:\n",
            "      container:\n",
            "        args:\n",
            "        - --executor_input\n",
            "        - '{{$}}'\n",
            "        - --function_to_execute\n",
            "        - feature_engineering\n",
            "        command:\n",
            "        - sh\n",
            "        - -c\n",
            "        - \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip ||\\\n",
            "          \\ python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1\\\n",
            "          \\ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.8.0'\\\n",
            "          \\ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\\\"3.9\\\"'  &&\\\n",
            "          \\  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'numpy'\\\n",
            "          \\ 'scikit-learn' && \\\"$0\\\" \\\"$@\\\"\\n\"\n",
            "        - sh\n",
            "        - -ec\n",
            "        - 'program_path=$(mktemp -d)\n",
            "\n",
            "\n",
            "          printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "\n",
            "          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\n",
            "          '\n",
            "        - \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import\\\n",
            "          \\ *\\n\\ndef feature_engineering(preprocessed_data_path: str) -> str:\\n  \\\n",
            "          \\  import pandas as pd\\n    import numpy as np\\n    from sklearn.impute\\\n",
            "          \\ import SimpleImputer\\n    from sklearn.model_selection import train_test_split\\n\\\n",
            "          \\    from sklearn.preprocessing import StandardScaler\\n    data = pd.read_csv(preprocessed_data_path)\\n\\\n",
            "          \\n    # Handle missing values\\n    imputer_num = SimpleImputer(strategy='median')\\n\\\n",
            "          \\    imputer_cat = SimpleImputer(strategy='most_frequent')\\n\\n    numeric_features\\\n",
            "          \\ = data.select_dtypes(include=[np.number]).columns\\n    categorical_features\\\n",
            "          \\ = data.select_dtypes(exclude=[np.number]).columns\\n\\n    data[numeric_features]\\\n",
            "          \\ = imputer_num.fit_transform(data[numeric_features])\\n    data[categorical_features]\\\n",
            "          \\ = imputer_cat.fit_transform(data[categorical_features])\\n\\n    # Splitting\\\n",
            "          \\ the data\\n    X = data.drop('spam', axis=1)\\n    y = data['spam']\\n\\n\\\n",
            "          \\    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\\\n",
            "          \\ random_state=42)\\n\\n    # Standardizing the data\\n    scaler = StandardScaler()\\n\\\n",
            "          \\    X_train = scaler.fit_transform(X_train)\\n    X_test = scaler.transform(X_test)\\n\\\n",
            "          \\n    # Save engineered features\\n    np.savez('engineered_features.npz',\\\n",
            "          \\ X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\\n    return\\\n",
            "          \\ 'engineered_features.npz'\\n\\n\"\n",
            "        image: python:3.9\n",
            "    exec-load-and-preprocess-data:\n",
            "      container:\n",
            "        args:\n",
            "        - --executor_input\n",
            "        - '{{$}}'\n",
            "        - --function_to_execute\n",
            "        - load_and_preprocess_data\n",
            "        command:\n",
            "        - sh\n",
            "        - -c\n",
            "        - \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip ||\\\n",
            "          \\ python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1\\\n",
            "          \\ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.8.0'\\\n",
            "          \\ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\\\"3.9\\\"'  &&\\\n",
            "          \\  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'numpy'\\\n",
            "          \\ && \\\"$0\\\" \\\"$@\\\"\\n\"\n",
            "        - sh\n",
            "        - -ec\n",
            "        - 'program_path=$(mktemp -d)\n",
            "\n",
            "\n",
            "          printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "\n",
            "          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\n",
            "          '\n",
            "        - \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import\\\n",
            "          \\ *\\n\\ndef load_and_preprocess_data() -> str:\\n    import numpy as np\\n\\\n",
            "          \\    import pandas as pd\\n    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\\n\\\n",
            "          \\    data = pd.read_csv(url, header=None)\\n\\n    columns = [\\\"word_freq_make\\\"\\\n",
            "          , \\\"word_freq_address\\\", \\\"word_freq_all\\\", \\\"word_freq_3d\\\", \\\"word_freq_our\\\"\\\n",
            "          ,\\n               \\\"word_freq_over\\\", \\\"word_freq_remove\\\", \\\"word_freq_internet\\\"\\\n",
            "          , \\\"word_freq_order\\\", \\\"word_freq_mail\\\",\\n               \\\"word_freq_receive\\\"\\\n",
            "          , \\\"word_freq_will\\\", \\\"word_freq_people\\\", \\\"word_freq_report\\\", \\\"word_freq_addresses\\\"\\\n",
            "          ,\\n               \\\"word_freq_free\\\", \\\"word_freq_business\\\", \\\"word_freq_email\\\"\\\n",
            "          , \\\"word_freq_you\\\", \\\"word_freq_credit\\\",\\n               \\\"word_freq_your\\\"\\\n",
            "          , \\\"word_freq_font\\\", \\\"word_freq_000\\\", \\\"word_freq_money\\\", \\\"word_freq_hp\\\"\\\n",
            "          ,\\n               \\\"word_freq_hpl\\\", \\\"word_freq_george\\\", \\\"word_freq_650\\\"\\\n",
            "          , \\\"word_freq_lab\\\", \\\"word_freq_labs\\\",\\n               \\\"word_freq_telnet\\\"\\\n",
            "          , \\\"word_freq_857\\\", \\\"word_freq_data\\\", \\\"word_freq_415\\\", \\\"word_freq_85\\\"\\\n",
            "          ,\\n               \\\"word_freq_technology\\\", \\\"word_freq_1999\\\", \\\"word_freq_parts\\\"\\\n",
            "          , \\\"word_freq_pm\\\", \\\"word_freq_direct\\\",\\n               \\\"word_freq_cs\\\"\\\n",
            "          , \\\"word_freq_meeting\\\", \\\"word_freq_original\\\", \\\"word_freq_project\\\",\\\n",
            "          \\ \\\"word_freq_re\\\",\\n               \\\"word_freq_edu\\\", \\\"word_freq_table\\\"\\\n",
            "          , \\\"word_freq_conference\\\", \\\"char_freq_;\\\", \\\"char_freq_(\\\",\\n        \\\n",
            "          \\       \\\"char_freq_[\\\", \\\"char_freq_!\\\", \\\"char_freq_$\\\", \\\"char_freq_#\\\"\\\n",
            "          , \\\"capital_run_length_average\\\",\\n               \\\"capital_run_length_longest\\\"\\\n",
            "          , \\\"capital_run_length_total\\\", \\\"spam\\\"]\\n    data.columns = columns\\n\\n\\\n",
            "          \\    # Save preprocessed data to CSV\\n    data.to_csv('preprocessed_data.csv',\\\n",
            "          \\ index=False)\\n    return 'preprocessed_data.csv'\\n\\n\"\n",
            "        image: python:3.9\n",
            "    exec-model-evaluation:\n",
            "      container:\n",
            "        args:\n",
            "        - --executor_input\n",
            "        - '{{$}}'\n",
            "        - --function_to_execute\n",
            "        - model_evaluation\n",
            "        command:\n",
            "        - sh\n",
            "        - -c\n",
            "        - \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip ||\\\n",
            "          \\ python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1\\\n",
            "          \\ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.8.0'\\\n",
            "          \\ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\\\"3.9\\\"'  &&\\\n",
            "          \\  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'tensorflow'\\\n",
            "          \\ 'keras' && \\\"$0\\\" \\\"$@\\\"\\n\"\n",
            "        - sh\n",
            "        - -ec\n",
            "        - 'program_path=$(mktemp -d)\n",
            "\n",
            "\n",
            "          printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "\n",
            "          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\n",
            "          '\n",
            "        - \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import\\\n",
            "          \\ *\\n\\ndef model_evaluation(trained_model_path: str, engineered_features_path:\\\n",
            "          \\ str):\\n    import numpy as np\\n    import tensorflow as tf\\n    from tensorflow\\\n",
            "          \\ import keras\\n    from tensorflow.keras.models import Sequential\\n   \\\n",
            "          \\ from tensorflow.keras.layers import Dense\\n    import matplotlib.pyplot\\\n",
            "          \\ as plt\\n\\n    data = np.load(engineered_features_path)\\n    X_test = data['X_test']\\n\\\n",
            "          \\    y_test = data['y_test']\\n\\n    model = keras.models.load_model(trained_model_path)\\n\\\n",
            "          \\    loss, accuracy = model.evaluate(X_test, y_test)\\n    print(f'Test Loss:\\\n",
            "          \\ {loss}')\\n    print(f'Test Accuracy: {accuracy}')\\n\\n    history_data\\\n",
            "          \\ = np.load('/mnt/data/training_history.npz', allow_pickle=True)\\n    history\\\n",
            "          \\ = history_data['history'].item()\\n\\n    plt.plot(history['loss'], label='train_loss')\\n\\\n",
            "          \\    plt.plot(history['val_loss'], label='val_loss')\\n    plt.xlabel('Epochs')\\n\\\n",
            "          \\    plt.ylabel('Loss')\\n    plt.legend()\\n    plt.savefig('/mnt/data/loss_plot.png')\\n\\\n",
            "          \\n\"\n",
            "        image: python:3.9\n",
            "    exec-model-training:\n",
            "      container:\n",
            "        args:\n",
            "        - --executor_input\n",
            "        - '{{$}}'\n",
            "        - --function_to_execute\n",
            "        - model_training\n",
            "        command:\n",
            "        - sh\n",
            "        - -c\n",
            "        - \"\\nif ! [ -x \\\"$(command -v pip)\\\" ]; then\\n    python3 -m ensurepip ||\\\n",
            "          \\ python3 -m ensurepip --user || apt-get install python3-pip\\nfi\\n\\nPIP_DISABLE_PIP_VERSION_CHECK=1\\\n",
            "          \\ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.8.0'\\\n",
            "          \\ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\\\"3.9\\\"'  &&\\\n",
            "          \\  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'tensorflow'\\\n",
            "          \\ 'keras' && \\\"$0\\\" \\\"$@\\\"\\n\"\n",
            "        - sh\n",
            "        - -ec\n",
            "        - 'program_path=$(mktemp -d)\n",
            "\n",
            "\n",
            "          printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "\n",
            "          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\n",
            "          '\n",
            "        - \"\\nimport kfp\\nfrom kfp import dsl\\nfrom kfp.dsl import *\\nfrom typing import\\\n",
            "          \\ *\\n\\ndef model_training(engineered_features_path: str) -> str:\\n    import\\\n",
            "          \\ numpy as np\\n    import tensorflow as tf\\n    from tensorflow import keras\\n\\\n",
            "          \\    from tensorflow.keras.models import Sequential\\n    from tensorflow.keras.layers\\\n",
            "          \\ import Dense\\n    data = np.load(engineered_features_path)\\n    X_train\\\n",
            "          \\ = data['X_train']\\n    X_test = data['X_test']\\n    y_train = data['y_train']\\n\\\n",
            "          \\    y_test = data['y_test']\\n\\n    model = Sequential()\\n    model.add(Dense(64,\\\n",
            "          \\ input_dim=X_train.shape[1], activation='relu'))\\n    model.add(Dense(32,\\\n",
            "          \\ activation='relu'))\\n    model.add(Dense(1, activation='sigmoid'))\\n\\n\\\n",
            "          \\    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\\n",
            "          \\n    history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)\\n\\\n",
            "          \\n    # Save the trained model\\n    model.save('spam_classification_model.h5')\\n\\\n",
            "          \\n    # Save the training history\\n    np.savez('training_history.npz',\\\n",
            "          \\ history=history.history)\\n    return 'spam_classification_model.h5'\\n\\n\"\n",
            "        image: python:3.9\n",
            "pipelineInfo:\n",
            "  description: A pipeline to train and classify emails as spam or not spam\n",
            "  name: spam-classification-pipeline\n",
            "root:\n",
            "  dag:\n",
            "    tasks:\n",
            "      eda:\n",
            "        cachingOptions:\n",
            "          enableCache: true\n",
            "        componentRef:\n",
            "          name: comp-eda\n",
            "        dependentTasks:\n",
            "        - load-and-preprocess-data\n",
            "        inputs:\n",
            "          parameters:\n",
            "            preprocessed_data_path:\n",
            "              taskOutputParameter:\n",
            "                outputParameterKey: Output\n",
            "                producerTask: load-and-preprocess-data\n",
            "        taskInfo:\n",
            "          name: eda\n",
            "      feature-engineering:\n",
            "        cachingOptions:\n",
            "          enableCache: true\n",
            "        componentRef:\n",
            "          name: comp-feature-engineering\n",
            "        dependentTasks:\n",
            "        - load-and-preprocess-data\n",
            "        inputs:\n",
            "          parameters:\n",
            "            preprocessed_data_path:\n",
            "              taskOutputParameter:\n",
            "                outputParameterKey: Output\n",
            "                producerTask: load-and-preprocess-data\n",
            "        taskInfo:\n",
            "          name: feature-engineering\n",
            "      load-and-preprocess-data:\n",
            "        cachingOptions:\n",
            "          enableCache: true\n",
            "        componentRef:\n",
            "          name: comp-load-and-preprocess-data\n",
            "        taskInfo:\n",
            "          name: load-and-preprocess-data\n",
            "      model-evaluation:\n",
            "        cachingOptions:\n",
            "          enableCache: true\n",
            "        componentRef:\n",
            "          name: comp-model-evaluation\n",
            "        dependentTasks:\n",
            "        - feature-engineering\n",
            "        - model-training\n",
            "        inputs:\n",
            "          parameters:\n",
            "            engineered_features_path:\n",
            "              taskOutputParameter:\n",
            "                outputParameterKey: Output\n",
            "                producerTask: feature-engineering\n",
            "            trained_model_path:\n",
            "              taskOutputParameter:\n",
            "                outputParameterKey: Output\n",
            "                producerTask: model-training\n",
            "        taskInfo:\n",
            "          name: model-evaluation\n",
            "      model-training:\n",
            "        cachingOptions:\n",
            "          enableCache: true\n",
            "        componentRef:\n",
            "          name: comp-model-training\n",
            "        dependentTasks:\n",
            "        - feature-engineering\n",
            "        inputs:\n",
            "          parameters:\n",
            "            engineered_features_path:\n",
            "              taskOutputParameter:\n",
            "                outputParameterKey: Output\n",
            "                producerTask: feature-engineering\n",
            "        taskInfo:\n",
            "          name: model-training\n",
            "schemaVersion: 2.1.0\n",
            "sdkVersion: kfp-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the KFP client, since the pipeline is compiled\n",
        "client = kfp.Client()\n",
        "\n",
        "# Specify experiment name\n",
        "experiment_name = \"spam_classification_experiment\"\n",
        "experiment = client.create_experiment(name=experiment_name)\n",
        "\n",
        "# Submit the pipeline run\n",
        "run_name = \"spam_classification_run\"\n",
        "run_result = client.run_pipeline(\n",
        "    experiment_id=experiment.id,\n",
        "    job_name=run_name,\n",
        "    pipeline_package_path='spam_classification_pipeline.yaml'\n",
        ")"
      ],
      "metadata": {
        "id": "9QKS7dch8qmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQ6dNxyx9DwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}